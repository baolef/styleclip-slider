{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542e1dbf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import clip\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "\n",
    "from embedding import get_delta_t\n",
    "from manipulator import Manipulator\n",
    "from mapper import get_delta_s\n",
    "from wrapper import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c17dfcd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# GPU device\n",
    "device = torch.device('cuda:1')\n",
    "# pretrained ffhq generator\n",
    "ckpt = 'pretrained/ffhq256.pkl'\n",
    "G = Generator(ckpt, device)\n",
    "# CLIP\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "# global image direction\n",
    "fs3 = np.load('tensor/fs3ffhq256.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf855a49",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "manipulator = Manipulator(G, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af5ce98c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test image dir path\n",
    "imgdir = 'samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e865b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading e4e over the pSp framework from checkpoint: pretrained/e4e_ffhq_encode.pt\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/baole/.conda/envs/zoom/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Loading e4e over the pSp framework from checkpoint: pretrained/e4e_ffhq_encode.pt\n"
     ]
    }
   ],
   "source": [
    "# manipulator mode\n",
    "# inv_mode : inversion mode\n",
    "    # 'w' : use w projector proposed by Karras et al.\n",
    "    # 'w+' : use e4e encoder (only implemented for ffhq1024 now)\n",
    "# pti_mode : pivot tuning mode\n",
    "    # 'w' : W latent space pivot tuning\n",
    "    # 's' : Style space pivot tuning\n",
    "manipulator.set_real_img_projection(imgdir, inv_mode='w', pti_mode='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd4d2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# prompt engineering\n",
    "templates = [\n",
    "    'a bad photo of a {}.',\n",
    "    'a photo of the hard to see {}.',\n",
    "    'a low resolution photo of the {}.',\n",
    "    'a rendering of a {}.',\n",
    "    'graffiti of a {}.',\n",
    "    'a bad photo of the {}.',\n",
    "    'a cropped photo of the {}.',\n",
    "    'a photo of a hard to see {}.',\n",
    "    'a bright photo of a {}.',\n",
    "    'a photo of a clean {}.',\n",
    "    'a photo of a dirty {}.',\n",
    "    'a dark photo of the {}.',\n",
    "    'a drawing of a {}.',\n",
    "    'a photo of my {}.',\n",
    "    'a photo of the cool {}.',\n",
    "    'a close-up photo of a {}.',\n",
    "    'a black and white photo of the {}.',\n",
    "    'a painting of the {}.',\n",
    "    'a painting of a {}.',\n",
    "    'a pixelated photo of the {}.',\n",
    "    'a sculpture of the {}.',\n",
    "    'a bright photo of the {}.',\n",
    "    'a cropped photo of a {}.',\n",
    "    'a jpeg corrupted photo of a {}.',\n",
    "    'a blurry photo of the {}.',\n",
    "    'a photo of the {}.',\n",
    "    'a good photo of the {}.',\n",
    "    'a rendering of the {}.',\n",
    "    'a close-up photo of the {}.',\n",
    "    'a photo of a {}.',\n",
    "    'a low resolution photo of a {}.',\n",
    "    'a photo of the clean {}.',\n",
    "    'a photo of a large {}.',\n",
    "    'a photo of a nice {}.',\n",
    "    'a blurry photo of a {}.',\n",
    "    'a cartoon {}.',\n",
    "    'art of a {}.',\n",
    "    'a good photo of a {}.',\n",
    "    'a photo of the nice {}.',\n",
    "    'a photo of the small {}.',\n",
    "    'a photo of the weird {}.',\n",
    "    'art of the {}.',\n",
    "    'a drawing of the {}.',\n",
    "    'a photo of the large {}.',\n",
    "    'a dark photo of a {}.',\n",
    "    'graffiti of the {}.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07276238",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# text direction : neutral -> target\n",
    "neutral = 'young face'\n",
    "target = 'old face'\n",
    "\n",
    "# beta_threshold : Determines the degree of disentanglement, # channels manipulated\n",
    "beta_threshold = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fddaa4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classnames=[neutral, target]\n",
    "# get delta_t in CLIP text space\n",
    "delta_t = get_delta_t(classnames, model)\n",
    "# get delta_s in global image directions and text directions that satisfy beta threshold\n",
    "delta_s, num_channel = get_delta_s(fs3, delta_t, manipulator, beta_threshold=beta_threshold)\n",
    "print(f'{num_channel} channels will be manipulated under the beta threshold {beta_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e014a6ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# alpha_threshold : Determines the degree of manipulation\n",
    "lst_alpha = [-2, -1, 0, 1, 2]\n",
    "manipulator.set_alpha(lst_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e22f95f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# manipulate styles\n",
    "styles = manipulator.manipulate(delta_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1df150",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# synthesis images from manipulated styles\n",
    "all_imgs = manipulator.synthesis_from_styles(styles, 0, manipulator.num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f12569",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# visualize\n",
    "lst = []\n",
    "for imgs in all_imgs:\n",
    "    lst.append((imgs.permute(0,2,3,1)*127.5+128).clamp(0,255).to(torch.uint8).numpy())\n",
    "\n",
    "H,W = (256,256)\n",
    "gw, gh = (manipulator.num_images, 1)\n",
    "\n",
    "for i, alpha in enumerate(lst_alpha):\n",
    "    print(alpha)\n",
    "    imgs = lst[i]\n",
    "    imgs_ = []    \n",
    "    for img in imgs:\n",
    "        imgs_.append( np.asarray( PIL.Image.fromarray(img, 'RGB').resize((H,W),PIL.Image.LANCZOS)))\n",
    "    imgs_ = np.stack(imgs_)\n",
    "    imgs_ = imgs_.reshape(gh,gw,H,W,3)\n",
    "    imgs_ = imgs_.transpose(0,2,1,3,4)\n",
    "    imgs_ = imgs_.reshape(gh*H, gw*W, 3)\n",
    "    display(PIL.Image.fromarray(imgs_, 'RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc6383",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}